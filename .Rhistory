ind <- sample(2, nrow(hc), replace=TRUE, prob=c(0.7, 0.3))
library(klaR)
ind <- sample(2, nrow(df), replace=TRUE, prob=c(0.7, 0.3))
hc_train <- data.frame(hc, clusters)
library(klaR)
ind <- sample(2, nrow(df), replace=TRUE, prob=c(0.7, 0.3))
hc_train <- data.frame(df, clusters)
hc_train <- hc_train[ind == 1, ]
hc_train$clusters <- as.factor(hc_train$clusters)
hc_test <- hc[ind == 2, ]
library(cluster)
library(factoextra)
library(ggplot2) # для визуализации данных
library(dplyr) # для манипуляций с данными
df <- read.csv("StudentsPerformance.csv", sep=",", header=T, fileEncoding="UTF-8")
str(df)
summary(df)
ggplot(df, aes(x=gender)) +
geom_bar(fill="#69b3a2") +
labs(title="Распределение по полу", x="Пол", y="Количество студентов")
ggplot(df, aes(x=race_ethnicity)) +
geom_bar(fill="#69b3a2") +
labs(title="Распределение по расе/этнической группе", x="Раса/этническая группа", y="Количество студентов")
ggplot(df, aes(x=parental_level_of_education)) +
geom_bar(fill="#69b3a2") +
labs(title="Распределение по уровню образования родителей", x="Уровень образования", y="Количество студентов")
ggplot(df, aes(x=lunch)) +
geom_bar(fill="#69b3a2") +
labs(title="Распределение по типу обеда", x="Тип обеда", y="Количество студентов")
ggplot(df, aes(x=test_preparation_course)) +
geom_bar(fill="#69b3a2") +
labs(title="Распределение по курсу подготовки к экзамену", x="Курс подготовки", y="Количество студентов")
ggplot(df, aes(x=math_score)) +
geom_histogram(fill="#69b3a2", binwidth=5) +
labs(title="Распределение оценок по математике", x="Оценка", y="Количество студентов")
ggplot(df, aes(x=reading_score)) +
geom_histogram(fill="#69b3a2", binwidth=5) +
labs(title="Распределение оценок по чтению", x="Оценка", y="Количество студентов")
ggplot(df, aes(x=writing_score)) +
geom_histogram(fill="#69b3a2", binwidth=5) +
labs(title="Распределение оценок по письму", x="Оценка", y="Количество студентов")
ggplot(df, aes(x=math_score, y=reading_score)) +
geom_point(color="#69b3a2") +
labs(title="Диаграмма рассеяния для оценок по математике и чтению", x="Оценка по математике", y="Оценка по чтению")
# Выбираем переменные для кластеризации
cluster_vars <- c("math_score", "reading_score", "writing_score")
# Создаем матрицу расстояний на основе выбранных переменных
d <- dist(df[, cluster_vars], method = "euclidean")
# Выполняем кластеризацию методом "полного" (complete) сцепления
hc <- hclust(d, method = "complete")
# Строим дендрограмму для визуализации кластеров
plot(hc, cex = 0.6, hang = -1, labels = df$race_ethnicity, main = "Dendrogram of StudentsPerformance data")
# Выбираем переменные для кластеризации
cluster_vars <- c("math_score", "reading_score", "writing_score")
# Создаем матрицу расстояний на основе выбранных переменных
d <- dist(df[, cluster_vars], method = "euclidean")
# Выполняем кластеризацию методом "полного" (complete) сцепления
hc <- hclust(d, method = "complete")
plot(hc, labels=F)
rect.hclust(hc,k = 5, border="red")
# Строим график для метода локтя
# метод локтя
fviz_nbclust(df[6:8], kmeans, method = 'wss')
plot(1:(nrow(df)-1), hc$height, type='b', main='Каменная осыпь')
df$average_score <- (df$math_score + df$reading_score + df$writing_score)/3
library(ggplot2)
ggplot(df, aes(x = parental_level_of_education, y = average_score)) +
geom_boxplot(fill = "lightblue") +
labs(title = "Зависимость между образованием родителей и успеваемостью студентов",
x = "Образование родителей", y = "Средняя оценка")
library (lattice)
clusters <- cutree(hc, k = 5)
xyplot(math_score~reading_score, group = clusters, data = df, auto.key = TRUE, col = rainbow(5))
cloud(math_score~reading_score*writing_score, group = clusters,  data = df,
auto.key = TRUE, col = rainbow(5))
library(klaR)
ind <- sample(2, nrow(df), replace=TRUE, prob=c(0.7, 0.3))
hc_train <- data.frame(hc, clusters)
hc_train <- data.frame(df[6:8], clusters)
library(klaR)
ind <- sample(2, nrow(df), replace=TRUE, prob=c(0.7, 0.3))
hc_train <- data.frame(df[6:8], clusters)
hc_train <- hc_train[ind == 1, ]
hc_train$clusters <- as.factor(hc_train$clusters)
hc_test <- hc[ind == 2, ]
library(klaR)
ind <- sample(2, nrow(df), replace=TRUE, prob=c(0.7, 0.3))
df_train <- data.frame(df[6:8], clusters)
df_train <- df_train[ind == 1, ]
df_train$clusters <- as.factor(df_train$clusters)
df_test <- df[ind == 2, ]
clusters_test <- clusters[ind == 2]
df_test <- data.frame(df_test, clusters=clusters_test)
naive_crashes <- NaiveBayes(clusters~., data=df_train)
library(klaR)
ind <- sample(2, nrow(df), replace=TRUE, prob=c(0.7, 0.3))
df_train <- data.frame(df[6:8], clusters)
df_train <- df_train[ind == 1, ]
df_train$clusters <- as.factor(df_train$clusters)
df_test <- df[ind == 2, ]
clusters_test <- clusters[ind == 2]
df_test <- data.frame(df_test, clusters=clusters_test)
naive_crashes <- NaiveBayes(clusters~., data=df_train)
library(klaR)
ind <- sample(2, nrow(df), replace=TRUE, prob=c(0.7, 0.3))
df_train <- data.frame(df[6:8], clusters)
df_train <- df_train[ind == 1, ]
df_train$clusters <- as.factor(df_train$clusters)
df_test <- df[ind == 2, ]
clusters_test <- clusters[ind == 2]
df_test <- data.frame(df_test, clusters=clusters_test)
naive_crashes <- NaiveBayes(clusters~., data=df_train)
naive_crashes$tables
par(mfrow=c(3,1))
plot(naive_crashes,lwd = 2, legendplot=FALSE)
pred_b <- predict(naive_crashes, df_train[, -4])$class
table(Факт = df_train$clusters, Прогноз = pred_b)
acc_b <- mean(pred_b == df_train$clusters)
paste0("Точность = ", round(100*acc_b, 2), "%")
library(party)
myFormula <- clusters ~ .
crashes_ctree <- ctree(myFormula, data=df_train)
pred_t <- predict(crashes_ctree, df_train[, -4])
table(Факт = df_train$clusters, Прогноз = pred_t)
acc_t <- mean(pred_t == df_train$clusters)
paste0("Точность = ", round(100*acc_t, 2), "%")
dev.off()
plot(crashes_ctree)
library(randomForest)
rf <- randomForest(clusters ~ ., data=df_train, ntree=100, proximity=TRUE)
pred_rf <- predict(crashes_ctree, df_train[, -4])
table(Факт = df_train$clusters, Прогноз = pred_rf)
acc_rf <- mean(pred_rf == df_train$clusters)
paste0("Точность = ", round(100*acc_rf, 2), "%")
library(klaR)
ind <- sample(2, nrow(df), replace=TRUE, prob=c(0.7, 0.3))
df_train <- data.frame(df[6:8], clusters)
df_train <- df_train[ind == 1, ]
df_train$clusters <- as.factor(df_train$clusters)
df_test <- df[ind == 2, ]
clusters_test <- clusters[ind == 2]
df_test <- data.frame(df_test, clusters=clusters_test)
naive_crashes <- NaiveBayes(clusters~., data=df_train)
naive_crashes$tables
par(mfrow=c(3,1))
plot(naive_crashes,lwd = 2, legendplot=FALSE)
pred_b <- predict(naive_crashes, df_train[, -4])$class
table(Факт = df_train$clusters, Прогноз = pred_b)
acc_b <- mean(pred_b == df_train$clusters)
paste0("Точность = ", round(100*acc_b, 2), "%")
library(party)
myFormula <- clusters ~ .
crashes_ctree <- ctree(myFormula, data=df_train)
pred_t <- predict(crashes_ctree, df_train[, -4])
table(Факт = df_train$clusters, Прогноз = pred_t)
acc_t <- mean(pred_t == df_train$clusters)
paste0("Точность = ", round(100*acc_t, 2), "%")
dev.off()
plot(crashes_ctree)
library(randomForest)
rf <- randomForest(clusters ~ ., data=df_train, ntree=100, proximity=TRUE)
pred_rf <- predict(crashes_ctree, df_train[, -4])
table(Факт = df_train$clusters, Прогноз = pred_rf)
acc_rf <- mean(pred_rf == df_train$clusters)
paste0("Точность = ", round(100*acc_rf, 2), "%")
library(cluster)
library(factoextra)
library(ggplot2) # для визуализации данных
library(dplyr) # для манипуляций с данными
df <- read.csv("StudentsPerformance.csv", sep=",", header=T, fileEncoding="UTF-8")
str(df)
summary(df)
ggplot(df, aes(x=gender)) +
geom_bar(fill="#69b3a2") +
labs(title="Распределение по полу", x="Пол", y="Количество студентов")
ggplot(df, aes(x=race_ethnicity)) +
geom_bar(fill="#69b3a2") +
labs(title="Распределение по расе/этнической группе", x="Раса/этническая группа", y="Количество студентов")
ggplot(df, aes(x=parental_level_of_education)) +
geom_bar(fill="#69b3a2") +
labs(title="Распределение по уровню образования родителей", x="Уровень образования", y="Количество студентов")
ggplot(df, aes(x=lunch)) +
geom_bar(fill="#69b3a2") +
labs(title="Распределение по типу обеда", x="Тип обеда", y="Количество студентов")
ggplot(df, aes(x=test_preparation_course)) +
geom_bar(fill="#69b3a2") +
labs(title="Распределение по курсу подготовки к экзамену", x="Курс подготовки", y="Количество студентов")
ggplot(df, aes(x=math_score)) +
geom_histogram(fill="#69b3a2", binwidth=5) +
labs(title="Распределение оценок по математике", x="Оценка", y="Количество студентов")
ggplot(df, aes(x=reading_score)) +
geom_histogram(fill="#69b3a2", binwidth=5) +
labs(title="Распределение оценок по чтению", x="Оценка", y="Количество студентов")
ggplot(df, aes(x=writing_score)) +
geom_histogram(fill="#69b3a2", binwidth=5) +
labs(title="Распределение оценок по письму", x="Оценка", y="Количество студентов")
ggplot(df, aes(x=math_score, y=reading_score)) +
geom_point(color="#69b3a2") +
labs(title="Диаграмма рассеяния для оценок по математике и чтению", x="Оценка по математике", y="Оценка по чтению")
# Выбираем переменные для кластеризации
cluster_vars <- c("math_score", "reading_score", "writing_score")
# Создаем матрицу расстояний на основе выбранных переменных
d <- dist(df[, cluster_vars], method = "euclidean")
# Выполняем кластеризацию методом "полного" (complete) сцепления
hc <- hclust(d, method = "complete")
# Строим дендрограмму для визуализации кластеров
plot(hc, cex = 0.6, hang = -1, labels = df$race_ethnicity, main = "Dendrogram of StudentsPerformance data")
# Выбираем переменные для кластеризации
cluster_vars <- c("math_score", "reading_score", "writing_score")
# Создаем матрицу расстояний на основе выбранных переменных
d <- dist(df[, cluster_vars], method = "euclidean")
# Выполняем кластеризацию методом "полного" (complete) сцепления
hc <- hclust(d, method = "complete")
plot(hc, labels=F)
rect.hclust(hc,k = 5, border="red")
# Строим график для метода локтя
# метод локтя
fviz_nbclust(df[6:8], kmeans, method = 'wss')
plot(1:(nrow(df)-1), hc$height, type='b', main='Каменная осыпь')
df$average_score <- (df$math_score + df$reading_score + df$writing_score)/3
library(ggplot2)
ggplot(df, aes(x = parental_level_of_education, y = average_score)) +
geom_boxplot(fill = "lightblue") +
labs(title = "Зависимость между образованием родителей и успеваемостью студентов",
x = "Образование родителей", y = "Средняя оценка")
library (lattice)
clusters <- cutree(hc, k = 5)
xyplot(math_score~reading_score, group = clusters, data = df, auto.key = TRUE, col = rainbow(5))
cloud(math_score~reading_score*writing_score, group = clusters,  data = df,
auto.key = TRUE, col = rainbow(5))
ggplot(df, aes(x=parental_level_of_education, y=(math_score+reading_score+writing_score)/3)) +
geom_point() +
labs(x="Образование родителей", y="Средняя оценка по всем предметам") +
theme_bw()
library(klaR)
ind <- sample(2, nrow(df), replace=TRUE, prob=c(0.7, 0.3))
df_train <- data.frame(df[6:8], clusters)
df_train <- df_train[ind == 1, ]
df_train$clusters <- as.factor(df_train$clusters)
df_test <- df[ind == 2, ]
clusters_test <- clusters[ind == 2]
df_test <- data.frame(df_test, clusters=clusters_test)
naive_crashes <- NaiveBayes(clusters~., data=df_train)
naive_crashes$tables
par(mfrow=c(3,1))
plot(naive_crashes,lwd = 2, legendplot=FALSE)
pred_b <- predict(naive_crashes, df_train[, -4])$class
table(Факт = df_train$clusters, Прогноз = pred_b)
acc_b <- mean(pred_b == df_train$clusters)
paste0("Точность = ", round(100*acc_b, 2), "%")
library(party)
myFormula <- clusters ~ .
crashes_ctree <- ctree(myFormula, data=df_train)
pred_t <- predict(crashes_ctree, df_train[, -4])
table(Факт = df_train$clusters, Прогноз = pred_t)
acc_t <- mean(pred_t == df_train$clusters)
paste0("Точность = ", round(100*acc_t, 2), "%")
dev.off()
plot(crashes_ctree)
library(randomForest)
rf <- randomForest(clusters ~ ., data=df_train, ntree=100, proximity=TRUE)
pred_rf <- predict(crashes_ctree, df_train[, -4])
table(Факт = df_train$clusters, Прогноз = pred_rf)
acc_rf <- mean(pred_rf == df_train$clusters)
paste0("Точность = ", round(100*acc_rf, 2), "%")
library(klaR)
ind <- sample(2, nrow(df), replace=TRUE, prob=c(0.7, 0.3))
df_train <- data.frame(df[6:8], clusters)
df_train <- df_train[ind == 1, ]
df_train$clusters <- as.factor(df_train$clusters)
df_test <- df[ind == 2, ]
clusters_test <- clusters[ind == 2]
df_test <- data.frame(df_test, clusters=clusters_test)
naive_crashes <- NaiveBayes(clusters~., data=df_train)
naive_crashes$tables
par(mfrow=c(3,1))
plot(naive_crashes,lwd = 2, legendplot=FALSE)
pred_b <- predict(naive_crashes, df_train[, -4])$class
table(Факт = df_train$clusters, Прогноз = pred_b)
acc_b <- mean(pred_b == df_train$clusters)
paste0("Точность = ", round(100*acc_b, 2), "%")
library(party)
myFormula <- clusters ~ .
crashes_ctree <- ctree(myFormula, data=df_train)
pred_t <- predict(crashes_ctree, df_train[, -4])
table(Факт = df_train$clusters, Прогноз = pred_t)
acc_t <- mean(pred_t == df_train$clusters)
paste0("Точность = ", round(100*acc_t, 2), "%")
dev.off()
plot(crashes_ctree)
acc_t <- mean(pred_t == df_train$clusters)
paste0("Точность = ", round(100*acc_t, 2), "%")
dev.off()
plot(crashes_ctree)
library(randomForest)
rf <- randomForest(clusters ~ ., data=df_train, ntree=100, proximity=TRUE)
pred_rf <- predict(crashes_ctree, df_train[, -4])
table(Факт = df_train$clusters, Прогноз = pred_rf)
acc_rf <- mean(pred_rf == df_train$clusters)
paste0("Точность = ", round(100*acc_rf, 2), "%")
pred_t <- predict(crashes_ctree, df_test[, -4])
table(Факт = df_test$clusters, Прогноз = pred_t)
acc_t <- mean(pred_t == df_test$clusters)
paste0("Точность = ", round(100*acc_t, 2), "%")
dev.off()
plot(crashes_ctree)
library(cluster)
library(factoextra)
library(ggplot2) # для визуализации данных
library(dplyr) # для манипуляций с данными
df <- read.csv("StudentsPerformance.csv", sep=",", header=T, fileEncoding="UTF-8")
str(df)
summary(df)
ggplot(df, aes(x=gender)) +
geom_bar(fill="#69b3a2") +
labs(title="Распределение по полу", x="Пол", y="Количество студентов")
ggplot(df, aes(x=race_ethnicity)) +
geom_bar(fill="#69b3a2") +
labs(title="Распределение по расе/этнической группе", x="Раса/этническая группа", y="Количество студентов")
ggplot(df, aes(x=parental_level_of_education)) +
geom_bar(fill="#69b3a2") +
labs(title="Распределение по уровню образования родителей", x="Уровень образования", y="Количество студентов")
ggplot(df, aes(x=lunch)) +
geom_bar(fill="#69b3a2") +
labs(title="Распределение по типу обеда", x="Тип обеда", y="Количество студентов")
ggplot(df, aes(x=test_preparation_course)) +
geom_bar(fill="#69b3a2") +
labs(title="Распределение по курсу подготовки к экзамену", x="Курс подготовки", y="Количество студентов")
ggplot(df, aes(x=math_score)) +
geom_histogram(fill="#69b3a2", binwidth=5) +
labs(title="Распределение оценок по математике", x="Оценка", y="Количество студентов")
ggplot(df, aes(x=reading_score)) +
geom_histogram(fill="#69b3a2", binwidth=5) +
labs(title="Распределение оценок по чтению", x="Оценка", y="Количество студентов")
ggplot(df, aes(x=writing_score)) +
geom_histogram(fill="#69b3a2", binwidth=5) +
labs(title="Распределение оценок по письму", x="Оценка", y="Количество студентов")
ggplot(df, aes(x=math_score, y=reading_score)) +
geom_point(color="#69b3a2") +
labs(title="Диаграмма рассеяния для оценок по математике и чтению", x="Оценка по математике", y="Оценка по чтению")
ggplot(df, aes(x=parental_level_of_education, y=(math_score+reading_score+writing_score)/3)) +
geom_point() +
labs(x="Образование родителей", y="Средняя оценка по всем предметам") +
theme_bw()
# Выбираем переменные для кластеризации
cluster_vars <- c("math_score", "reading_score", "writing_score")
# Создаем матрицу расстояний на основе выбранных переменных
d <- dist(df[, cluster_vars], method = "euclidean")
# Выполняем кластеризацию методом "полного" (complete) сцепления
hc <- hclust(d, method = "complete")
# Строим дендрограмму для визуализации кластеров
plot(hc, cex = 0.6, hang = -1, labels = df$race_ethnicity, main = "Dendrogram of StudentsPerformance data")
# Выбираем переменные для кластеризации
cluster_vars <- c("math_score", "reading_score", "writing_score")
# Создаем матрицу расстояний на основе выбранных переменных
d <- dist(df[, cluster_vars], method = "euclidean")
# Выполняем кластеризацию методом "полного" (complete) сцепления
hc <- hclust(d, method = "complete")
plot(hc, labels=F)
rect.hclust(hc,k = 5, border="red")
# Строим график для метода локтя
# метод локтя
fviz_nbclust(df[6:8], kmeans, method = 'wss')
plot(1:(nrow(df)-1), hc$height, type='b', main='Каменная осыпь')
df$average_score <- (df$math_score + df$reading_score + df$writing_score)/3
library(ggplot2)
ggplot(df, aes(x = parental_level_of_education, y = average_score)) +
geom_boxplot(fill = "lightblue") +
labs(title = "Зависимость между образованием родителей и успеваемостью студентов",
x = "Образование родителей", y = "Средняя оценка")
library (lattice)
clusters <- cutree(hc, k = 5)
xyplot(math_score~reading_score, group = clusters, data = df, auto.key = TRUE, col = rainbow(5))
cloud(math_score~reading_score*writing_score, group = clusters,  data = df,
auto.key = TRUE, col = rainbow(5))
View(df)
View(df)
library(klaR)
ind <- sample(2, nrow(df), replace=TRUE, prob=c(0.7, 0.3))
df_train <- data.frame(df[6:8], clusters)
df_train <- df_train[ind == 1, ]
df_train$clusters <- as.factor(df_train$clusters)
df_test <- df[ind == 2, ]
clusters_test <- clusters[ind == 2]
df_test <- data.frame(df_test, clusters=clusters_test)
naive_crashes <- NaiveBayes(clusters~., data=df_train)
naive_crashes$tables
par(mfrow=c(3,1))
plot(naive_crashes,lwd = 2, legendplot=FALSE)
pred_b <- predict(naive_crashes, df_train[, -4])$class
table(Факт = df_train$clusters, Прогноз = pred_b)
acc_b <- mean(pred_b == df_train$clusters)
paste0("Точность = ", round(100*acc_b, 2), "%")
library(party)
myFormula <- clusters ~ .
crashes_ctree <- ctree(myFormula, data=df_train)
pred_t <- predict(crashes_ctree, df_test[, -4])
table(Факт = df_test$clusters, Прогноз = pred_t)
acc_t <- mean(pred_t == df_test$clusters)
paste0("Точность = ", round(100*acc_t, 2), "%")
dev.off()
plot(crashes_ctree)
library(randomForest)
rf <- randomForest(clusters ~ ., data=df_train, ntree=100, proximity=TRUE)
pred_rf <- predict(crashes_ctree, df_train[, -4])
table(Факт = df_train$clusters, Прогноз = pred_rf)
acc_rf <- mean(pred_rf == df_train$clusters)
paste0("Точность = ", round(100*acc_rf, 2), "%")
df <- read.csv("athlete_events.csv", sep=",", header=T,
fileEncoding="UTF-8", )
# все гребцы
rowing <- df[df$Sport == 'Rowing' & !is.na(df$Weight), ]
h0 <- mean(df[!df$Sport == 'Rowing' & !is.na(df$Weight), ]$Weight)
t.test(rowing$Weight, mu=h0)
taekwondo_M <- df[df$Sport == 'Taekwondo' & !is.na(df$Weight) & df$Sex == 'M', ]
taekwondo_F <- df[df$Sport == 'Taekwondo' & !is.na(df$Weight) & df$Sex == 'F', ]
judo_M <- df[df$Sport == 'Judo' & !is.na(df$Weight) & df$Sex == 'M', ]
judo_F <- df[df$Sport == 'Judo' & !is.na(df$Weight) & df$Sex == 'F', ]
library(car)
par(mfrow=c(1, 2))
qqPlot(judo_M$Weight, main='Вес мужчин дзюдоистов')
qqPlot(judo_F$Weight, main='Вес женщин дзюдоистов')
hist(judo_M$Weight, freq = FALSE, ylim = c(0, 0.025),
main = "Вес мужчин дзюдоистов")
lines(density(judo_M$Weight), col = "red", lwd = 2)
hist(judo_F$Weight, freq = FALSE, main = "Вес женщин дзюдоистов")
lines(density(judo_F$Weight), col = "red", lwd = 2)
shapiro.test(judo_M$Weight)
shapiro.test(judo_F$Weight)
qqPlot(taekwondo_M$Weight, main='Вес мужчин таэквондистов')
qqPlot(taekwondo_F$Weight, main='Вес женщин таэквондистов')
hist(taekwondo_M$Weight, freq = FALSE, main = "Вес мужчин таэквондистов")
lines(density(taekwondo_M$Weight), col = "red", lwd = 2)
hist(taekwondo_F$Weight, freq = FALSE, main = "Вес женщин таэквондистов")
lines(density(taekwondo_F$Weight), col = "red", lwd = 2)
shapiro.test(taekwondo_M$Weight)
shapiro.test(taekwondo_F$Weight)
judo_taekwondo_M <- rbind(judo_M, taekwondo_M)
judo_taekwondo_F <- rbind(judo_F, taekwondo_F)
bartlett.test(Weight ~ Sport, data=judo_taekwondo_M)
bartlett.test(Weight ~ Sport, data=judo_taekwondo_F)
t.test(Weight ~ Sport, data=judo_taekwondo_M)
t.test(Weight ~ Sport, data=judo_taekwondo_F)
df <- read.csv("athlete_events.csv", sep=",", header=T,
fileEncoding="UTF-8", )
View(df)
View(df)
df <- read.csv("athlete_events.csv", sep=",", header=T,
fileEncoding="UTF-8", )
# все гребцы
rowing <- df[df$Sport == '
Gymnastics' & !is.na(df$Weight), ]
h0 <- mean(df[!df$Sport == '
Gymnastics' & !is.na(df$Weight), ]$Weight)
t.test(rowing$Weight, mu=h0)
df <- read.csv("athlete_events.csv", sep=",", header=T,
fileEncoding="UTF-8", )
# все гребцы
rowing <- df[df$Sport == 'Rowing' & !is.na(df$Weight), ]
h0 <- mean(df[!df$Sport == 'Rowing' & !is.na(df$Weight), ]$Weight)
t.test(rowing$Weight, mu=h0)
df <- read.csv("athlete_events.csv", sep=",", header=T,
fileEncoding="UTF-8", )
# все гребцы
rowing <- df[df$Sport == 'Gymnastics' & !is.na(df$Weight), ]
h0 <- mean(df[!df$Sport == 'Gymnastics' & !is.na(df$Weight), ]$Weight)
t.test(rowing$Weight, mu=h0)
df <- read.csv("athlete_events.csv", sep=",", header=T,
fileEncoding="UTF-8", )
rowing <- df[df$Sport == 'Gymnastics' & !is.na(df$Weight), ]
h0 <- mean(df[!df$Sport == 'Gymnastics' & !is.na(df$Weight), ]$Weight)
t.test(rowing$Weight, mu=h0)
h0
Gymnastics <- df[df$Sport == 'Gymnastics' & !is.na(df$Weight), ]
h0 <- mean(df[!df$Sport == 'Gymnastics' & !is.na(df$Weight), ]$Weight)
h0
df <- read.csv("athlete_events.csv", sep=",", header=T,
fileEncoding="UTF-8", )
# все гребцы
Gymnastics <- df[df$Sport == 'Gymnastics' & !is.na(df$Weight), ]
h0 <- mean(df[!df$Sport == 'Gymnastics' & !is.na(df$Weight), ]$Weight)
h0
t.test(Gymnastics$Weight, mu=h0)
taekwondo_M <- df[df$Sport == 'Taekwondo' & !is.na(df$Weight) & df$Sex == 'M', ]
taekwondo_F <- df[df$Sport == 'Taekwondo' & !is.na(df$Weight) & df$Sex == 'F', ]
judo_M <- df[df$Sport == 'Judo' & !is.na(df$Weight) & df$Sex == 'M', ]
judo_F <- df[df$Sport == 'Judo' & !is.na(df$Weight) & df$Sex == 'F', ]
library(car)
par(mfrow=c(1, 2))
qqPlot(judo_M$Weight, main='Вес мужчин дзюдоистов')
qqPlot(judo_F$Weight, main='Вес женщин дзюдоистов')
hist(judo_M$Weight, freq = FALSE, ylim = c(0, 0.025),
main = "Вес мужчин дзюдоистов")
lines(density(judo_M$Weight), col = "red", lwd = 2)
hist(judo_F$Weight, freq = FALSE, main = "Вес женщин дзюдоистов")
lines(density(judo_F$Weight), col = "red", lwd = 2)
shapiro.test(judo_M$Weight)
shapiro.test(judo_F$Weight)
qqPlot(taekwondo_M$Weight, main='Вес мужчин таэквондистов')
qqPlot(taekwondo_F$Weight, main='Вес женщин таэквондистов')
hist(taekwondo_M$Weight, freq = FALSE, main = "Вес мужчин таэквондистов")
lines(density(taekwondo_M$Weight), col = "red", lwd = 2)
hist(taekwondo_F$Weight, freq = FALSE, main = "Вес женщин таэквондистов")
lines(density(taekwondo_F$Weight), col = "red", lwd = 2)
shapiro.test(taekwondo_M$Weight)
shapiro.test(taekwondo_F$Weight)
judo_taekwondo_M <- rbind(judo_M, taekwondo_M)
judo_taekwondo_F <- rbind(judo_F, taekwondo_F)
bartlett.test(Weight ~ Sport, data=judo_taekwondo_M)
bartlett.test(Weight ~ Sport, data=judo_taekwondo_F)
t.test(Weight ~ Sport, data=judo_taekwondo_M)
t.test(Weight ~ Sport, data=judo_taekwondo_F)
